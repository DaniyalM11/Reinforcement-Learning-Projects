{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frozen Lake\n",
    "### by Daniyal Mufti\n",
    "### Based on Hugging Face Course on Deep Reinforcement Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "9XaULfDZDvrC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gym==0.24\n",
      "  Using cached gym-0.24.0-py3-none-any.whl\n",
      "Requirement already satisfied: pygame in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit2/requirements-unit2.txt (line 2)) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit2/requirements-unit2.txt (line 3)) (1.22.4)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit2/requirements-unit2.txt (line 5)) (0.11.1)\n",
      "Collecting pickle5\n",
      "  Using cached pickle5-0.0.11.tar.gz (132 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: pyyaml==6.0 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit2/requirements-unit2.txt (line 7)) (6.0)\n",
      "Requirement already satisfied: imageio in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit2/requirements-unit2.txt (line 8)) (2.19.3)\n",
      "Requirement already satisfied: imageio_ffmpeg in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit2/requirements-unit2.txt (line 9)) (0.4.7)\n",
      "Requirement already satisfied: pyglet==1.5.1 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit2/requirements-unit2.txt (line 10)) (1.5.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit2/requirements-unit2.txt (line 11)) (4.62.3)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from gym==0.24->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit2/requirements-unit2.txt (line 1)) (4.13.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from gym==0.24->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit2/requirements-unit2.txt (line 1)) (2.0.0)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from gym==0.24->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit2/requirements-unit2.txt (line 1)) (0.0.8)\n",
      "Requirement already satisfied: filelock in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from huggingface_hub->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit2/requirements-unit2.txt (line 5)) (3.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from huggingface_hub->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit2/requirements-unit2.txt (line 5)) (22.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from huggingface_hub->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit2/requirements-unit2.txt (line 5)) (4.4.0)\n",
      "Requirement already satisfied: requests in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from huggingface_hub->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit2/requirements-unit2.txt (line 5)) (2.28.1)\n",
      "Requirement already satisfied: pillow>=8.3.2 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from imageio->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit2/requirements-unit2.txt (line 8)) (9.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from tqdm->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit2/requirements-unit2.txt (line 11)) (0.4.6)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from importlib-metadata>=4.8.0->gym==0.24->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit2/requirements-unit2.txt (line 1)) (3.11.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from requests->huggingface_hub->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit2/requirements-unit2.txt (line 5)) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from requests->huggingface_hub->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit2/requirements-unit2.txt (line 5)) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from requests->huggingface_hub->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit2/requirements-unit2.txt (line 5)) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from requests->huggingface_hub->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit2/requirements-unit2.txt (line 5)) (2.1.1)\n",
      "Building wheels for collected packages: pickle5\n",
      "  Building wheel for pickle5 (setup.py): started\n",
      "  Building wheel for pickle5 (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for pickle5\n",
      "Failed to build pickle5\n",
      "Installing collected packages: pickle5, gym\n",
      "  Running setup.py install for pickle5: started\n",
      "  Running setup.py install for pickle5: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py bdist_wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [38 lines of output]\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-38\n",
      "  creating build\\lib.win-amd64-cpython-38\\pickle5\n",
      "  copying pickle5\\pickle.py -> build\\lib.win-amd64-cpython-38\\pickle5\n",
      "  copying pickle5\\pickletools.py -> build\\lib.win-amd64-cpython-38\\pickle5\n",
      "  copying pickle5\\__init__.py -> build\\lib.win-amd64-cpython-38\\pickle5\n",
      "  creating build\\lib.win-amd64-cpython-38\\pickle5\\test\n",
      "  copying pickle5\\test\\pickletester.py -> build\\lib.win-amd64-cpython-38\\pickle5\\test\n",
      "  copying pickle5\\test\\test_pickle.py -> build\\lib.win-amd64-cpython-38\\pickle5\\test\n",
      "  copying pickle5\\test\\test_picklebuffer.py -> build\\lib.win-amd64-cpython-38\\pickle5\\test\n",
      "  copying pickle5\\test\\__init__.py -> build\\lib.win-amd64-cpython-38\\pickle5\\test\n",
      "  running build_ext\n",
      "  building 'pickle5._pickle' extension\n",
      "  creating build\\temp.win-amd64-cpython-38\n",
      "  creating build\\temp.win-amd64-cpython-38\\Release\n",
      "  creating build\\temp.win-amd64-cpython-38\\Release\\pickle5\n",
      "  \"C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.31.31103\\bin\\HostX86\\x64\\cl.exe\" /c /nologo /O2 /W3 /GL /DNDEBUG /MD -IC:\\Users\\Daniy\\Anaconda3\\envs\\tensorflow25\\include -IC:\\Users\\Daniy\\Anaconda3\\envs\\tensorflow25\\Include \"-IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.31.31103\\ATLMFC\\include\" \"-IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.31.31103\\include\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\winrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\cppwinrt\" /Tcpickle5/_pickle.c /Fobuild\\temp.win-amd64-cpython-38\\Release\\pickle5/_pickle.obj\n",
      "  _pickle.c\n",
      "  \"C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.31.31103\\bin\\HostX86\\x64\\cl.exe\" /c /nologo /O2 /W3 /GL /DNDEBUG /MD -IC:\\Users\\Daniy\\Anaconda3\\envs\\tensorflow25\\include -IC:\\Users\\Daniy\\Anaconda3\\envs\\tensorflow25\\Include \"-IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.31.31103\\ATLMFC\\include\" \"-IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.31.31103\\include\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\winrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\cppwinrt\" /Tcpickle5/picklebufobject.c /Fobuild\\temp.win-amd64-cpython-38\\Release\\pickle5/picklebufobject.obj\n",
      "  picklebufobject.c\n",
      "  pickle5/picklebufobject.c(19): warning C4273: 'PyPickleBuffer_FromObject': inconsistent dll linkage\n",
      "  C:\\Users\\Daniy\\Anaconda3\\envs\\tensorflow25\\include\\picklebufobject.h(18): note: see previous definition of 'PyPickleBuffer_FromObject'\n",
      "  pickle5/picklebufobject.c(38): warning C4273: 'PyPickleBuffer_GetBuffer': inconsistent dll linkage\n",
      "  C:\\Users\\Daniy\\Anaconda3\\envs\\tensorflow25\\include\\picklebufobject.h(22): note: see previous definition of 'PyPickleBuffer_GetBuffer'\n",
      "  pickle5/picklebufobject.c(57): warning C4273: 'PyPickleBuffer_Release': inconsistent dll linkage\n",
      "  C:\\Users\\Daniy\\Anaconda3\\envs\\tensorflow25\\include\\picklebufobject.h(24): note: see previous definition of 'PyPickleBuffer_Release'\n",
      "  pickle5/picklebufobject.c(208): warning C4273: 'PyPickleBuffer_Type': inconsistent dll linkage\n",
      "  C:\\Users\\Daniy\\Anaconda3\\envs\\tensorflow25\\include\\picklebufobject.h(13): note: see previous definition of 'PyPickleBuffer_Type'\n",
      "  \"C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.31.31103\\bin\\HostX86\\x64\\link.exe\" /nologo /INCREMENTAL:NO /LTCG /DLL /MANIFEST:EMBED,ID=2 /MANIFESTUAC:NO /LIBPATH:C:\\Users\\Daniy\\Anaconda3\\envs\\tensorflow25\\libs /LIBPATH:C:\\Users\\Daniy\\Anaconda3\\envs\\tensorflow25 /LIBPATH:C:\\Users\\Daniy\\Anaconda3\\envs\\tensorflow25\\PCbuild\\amd64 \"/LIBPATH:C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.31.31103\\ATLMFC\\lib\\x64\" \"/LIBPATH:C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.31.31103\\lib\\x64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.19041.0\\ucrt\\x64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\\\lib\\10.0.19041.0\\\\um\\x64\" /EXPORT:PyInit__pickle build\\temp.win-amd64-cpython-38\\Release\\pickle5/_pickle.obj build\\temp.win-amd64-cpython-38\\Release\\pickle5/picklebufobject.obj /OUT:build\\lib.win-amd64-cpython-38\\pickle5\\_pickle.cp38-win_amd64.pyd /IMPLIB:build\\temp.win-amd64-cpython-38\\Release\\pickle5\\_pickle.cp38-win_amd64.lib\n",
      "     Creating library build\\temp.win-amd64-cpython-38\\Release\\pickle5\\_pickle.cp38-win_amd64.lib and object build\\temp.win-amd64-cpython-38\\Release\\pickle5\\_pickle.cp38-win_amd64.exp\n",
      "  Generating code\n",
      "  Finished generating code\n",
      "  picklebufobject.obj : error LNK2005: PyPickleBuffer_GetBuffer already defined in python38.lib(python38.dll)\n",
      "  build\\lib.win-amd64-cpython-38\\pickle5\\_pickle.cp38-win_amd64.pyd : fatal error LNK1169: one or more multiply defined symbols found\n",
      "  error: command 'C:\\\\Program Files\\\\Microsoft Visual Studio\\\\2022\\\\Community\\\\VC\\\\Tools\\\\MSVC\\\\14.31.31103\\\\bin\\\\HostX86\\\\x64\\\\link.exe' failed with exit code 1169\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for pickle5\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Running setup.py install for pickle5 did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [40 lines of output]\n",
      "  running install\n",
      "  C:\\Users\\Daniy\\Anaconda3\\envs\\tensorflow25\\lib\\site-packages\\setuptools\\command\\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "    warnings.warn(\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-38\n",
      "  creating build\\lib.win-amd64-cpython-38\\pickle5\n",
      "  copying pickle5\\pickle.py -> build\\lib.win-amd64-cpython-38\\pickle5\n",
      "  copying pickle5\\pickletools.py -> build\\lib.win-amd64-cpython-38\\pickle5\n",
      "  copying pickle5\\__init__.py -> build\\lib.win-amd64-cpython-38\\pickle5\n",
      "  creating build\\lib.win-amd64-cpython-38\\pickle5\\test\n",
      "  copying pickle5\\test\\pickletester.py -> build\\lib.win-amd64-cpython-38\\pickle5\\test\n",
      "  copying pickle5\\test\\test_pickle.py -> build\\lib.win-amd64-cpython-38\\pickle5\\test\n",
      "  copying pickle5\\test\\test_picklebuffer.py -> build\\lib.win-amd64-cpython-38\\pickle5\\test\n",
      "  copying pickle5\\test\\__init__.py -> build\\lib.win-amd64-cpython-38\\pickle5\\test\n",
      "  running build_ext\n",
      "  building 'pickle5._pickle' extension\n",
      "  creating build\\temp.win-amd64-cpython-38\n",
      "  creating build\\temp.win-amd64-cpython-38\\Release\n",
      "  creating build\\temp.win-amd64-cpython-38\\Release\\pickle5\n",
      "  \"C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.31.31103\\bin\\HostX86\\x64\\cl.exe\" /c /nologo /O2 /W3 /GL /DNDEBUG /MD -IC:\\Users\\Daniy\\Anaconda3\\envs\\tensorflow25\\include -IC:\\Users\\Daniy\\Anaconda3\\envs\\tensorflow25\\Include \"-IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.31.31103\\ATLMFC\\include\" \"-IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.31.31103\\include\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\winrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\cppwinrt\" /Tcpickle5/_pickle.c /Fobuild\\temp.win-amd64-cpython-38\\Release\\pickle5/_pickle.obj\n",
      "  _pickle.c\n",
      "  \"C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.31.31103\\bin\\HostX86\\x64\\cl.exe\" /c /nologo /O2 /W3 /GL /DNDEBUG /MD -IC:\\Users\\Daniy\\Anaconda3\\envs\\tensorflow25\\include -IC:\\Users\\Daniy\\Anaconda3\\envs\\tensorflow25\\Include \"-IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.31.31103\\ATLMFC\\include\" \"-IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.31.31103\\include\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\winrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\cppwinrt\" /Tcpickle5/picklebufobject.c /Fobuild\\temp.win-amd64-cpython-38\\Release\\pickle5/picklebufobject.obj\n",
      "  picklebufobject.c\n",
      "  pickle5/picklebufobject.c(19): warning C4273: 'PyPickleBuffer_FromObject': inconsistent dll linkage\n",
      "  C:\\Users\\Daniy\\Anaconda3\\envs\\tensorflow25\\include\\picklebufobject.h(18): note: see previous definition of 'PyPickleBuffer_FromObject'\n",
      "  pickle5/picklebufobject.c(38): warning C4273: 'PyPickleBuffer_GetBuffer': inconsistent dll linkage\n",
      "  C:\\Users\\Daniy\\Anaconda3\\envs\\tensorflow25\\include\\picklebufobject.h(22): note: see previous definition of 'PyPickleBuffer_GetBuffer'\n",
      "  pickle5/picklebufobject.c(57): warning C4273: 'PyPickleBuffer_Release': inconsistent dll linkage\n",
      "  C:\\Users\\Daniy\\Anaconda3\\envs\\tensorflow25\\include\\picklebufobject.h(24): note: see previous definition of 'PyPickleBuffer_Release'\n",
      "  pickle5/picklebufobject.c(208): warning C4273: 'PyPickleBuffer_Type': inconsistent dll linkage\n",
      "  C:\\Users\\Daniy\\Anaconda3\\envs\\tensorflow25\\include\\picklebufobject.h(13): note: see previous definition of 'PyPickleBuffer_Type'\n",
      "  \"C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.31.31103\\bin\\HostX86\\x64\\link.exe\" /nologo /INCREMENTAL:NO /LTCG /DLL /MANIFEST:EMBED,ID=2 /MANIFESTUAC:NO /LIBPATH:C:\\Users\\Daniy\\Anaconda3\\envs\\tensorflow25\\libs /LIBPATH:C:\\Users\\Daniy\\Anaconda3\\envs\\tensorflow25 /LIBPATH:C:\\Users\\Daniy\\Anaconda3\\envs\\tensorflow25\\PCbuild\\amd64 \"/LIBPATH:C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.31.31103\\ATLMFC\\lib\\x64\" \"/LIBPATH:C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.31.31103\\lib\\x64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.19041.0\\ucrt\\x64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\\\lib\\10.0.19041.0\\\\um\\x64\" /EXPORT:PyInit__pickle build\\temp.win-amd64-cpython-38\\Release\\pickle5/_pickle.obj build\\temp.win-amd64-cpython-38\\Release\\pickle5/picklebufobject.obj /OUT:build\\lib.win-amd64-cpython-38\\pickle5\\_pickle.cp38-win_amd64.pyd /IMPLIB:build\\temp.win-amd64-cpython-38\\Release\\pickle5\\_pickle.cp38-win_amd64.lib\n",
      "     Creating library build\\temp.win-amd64-cpython-38\\Release\\pickle5\\_pickle.cp38-win_amd64.lib and object build\\temp.win-amd64-cpython-38\\Release\\pickle5\\_pickle.cp38-win_amd64.exp\n",
      "  Generating code\n",
      "  Finished generating code\n",
      "  picklebufobject.obj : error LNK2005: PyPickleBuffer_GetBuffer already defined in python38.lib(python38.dll)\n",
      "  build\\lib.win-amd64-cpython-38\\pickle5\\_pickle.cp38-win_amd64.pyd : fatal error LNK1169: one or more multiply defined symbols found\n",
      "  error: command 'C:\\\\Program Files\\\\Microsoft Visual Studio\\\\2022\\\\Community\\\\VC\\\\Tools\\\\MSVC\\\\14.31.31103\\\\bin\\\\HostX86\\\\x64\\\\link.exe' failed with exit code 1169\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: legacy-install-failure\n",
      "\n",
      "Encountered error while trying to install package.\n",
      "\n",
      "pickle5\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for output from the failure.\n"
     ]
    }
   ],
   "source": [
    "!pip install -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit2/requirements-unit2.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "n71uTX7qqzz2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: swig in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (4.1.1)\n",
      "Requirement already satisfied: cmake in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (3.25.0)\n",
      "Requirement already satisfied: stable-baselines3[extra] in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (1.6.2)\n",
      "Requirement already satisfied: box2d in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 2)) (2.3.10)\n",
      "Requirement already satisfied: box2d-kengz in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 3)) (2.3.3)\n",
      "Requirement already satisfied: huggingface_sb3 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 4)) (2.2.4)\n",
      "Requirement already satisfied: pyglet==1.5.1 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 5)) (1.5.1)\n",
      "Requirement already satisfied: importlib-metadata~=4.13 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (4.13.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: torch>=1.11 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (1.13.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (1.22.4)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (2.0.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (3.3.4)\n",
      "Collecting gym==0.21\n",
      "  Using cached gym-0.21.0-py3-none-any.whl\n",
      "Requirement already satisfied: opencv-python in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (4.7.0.68)\n",
      "Requirement already satisfied: autorom[accept-rom-license]~=0.4.2 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (0.4.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (4.62.3)\n",
      "Requirement already satisfied: psutil in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (5.9.0)\n",
      "Requirement already satisfied: ale-py==0.7.4 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (0.7.4)\n",
      "Requirement already satisfied: tensorboard>=2.9.1 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (2.10.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (9.2.0)\n",
      "Requirement already satisfied: rich in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (13.0.1)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from ale-py==0.7.4->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (5.4.0)\n",
      "Requirement already satisfied: pyyaml~=6.0 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from huggingface_sb3->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 4)) (6.0)\n",
      "Requirement already satisfied: wasabi in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from huggingface_sb3->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 4)) (1.1.0)\n",
      "Requirement already satisfied: huggingface-hub~=0.8 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from huggingface_sb3->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 4)) (0.11.1)\n",
      "Requirement already satisfied: requests in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (2.28.1)\n",
      "Requirement already satisfied: click in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (8.0.4)\n",
      "Requirement already satisfied: AutoROM.accept-rom-license in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (0.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from huggingface-hub~=0.8->huggingface_sb3->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 4)) (22.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from huggingface-hub~=0.8->huggingface_sb3->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 4)) (4.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from huggingface-hub~=0.8->huggingface_sb3->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 4)) (3.9.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from importlib-metadata~=4.13->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (3.11.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (0.6.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (3.19.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (1.8.1)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (0.38.4)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (65.6.3)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (1.51.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (2.15.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (2.2.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from matplotlib->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from matplotlib->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from matplotlib->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (0.11.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from matplotlib->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (3.0.9)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from pandas->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (2022.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from rich->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (2.11.2)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from rich->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (0.9.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from tqdm->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (0.4.6)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (1.26.13)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (3.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (2.1.1)\n",
      "Requirement already satisfied: libtorrent in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from AutoROM.accept-rom-license->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (2.0.7)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (3.2.2)\n",
      "Installing collected packages: gym\n",
      "  Attempting uninstall: gym\n",
      "    Found existing installation: gym 0.26.2\n",
      "    Uninstalling gym-0.26.2:\n",
      "      Successfully uninstalled gym-0.26.2\n",
      "Successfully installed gym-0.21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement get (from versions: none)\n",
      "ERROR: No matching distribution found for get\n",
      "ERROR: Could not find a version that satisfies the requirement python-opengl (from versions: none)\n",
      "ERROR: No matching distribution found for python-opengl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ffmpeg in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (1.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement xvfb (from versions: none)\n",
      "ERROR: No matching distribution found for xvfb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyvirtualdisplay in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (3.0)\n",
      "Requirement already satisfied: imageio-ffmpeg in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (0.4.7)\n",
      "Requirement already satisfied: gym in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (0.21.0)\n",
      "Collecting gym\n",
      "  Using cached gym-0.26.2-py3-none-any.whl\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from gym) (0.0.8)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from gym) (1.22.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from gym) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from gym) (4.13.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from importlib-metadata>=4.8.0->gym) (3.11.0)\n",
      "Installing collected packages: gym\n",
      "  Attempting uninstall: gym\n",
      "    Found existing installation: gym 0.21.0\n",
      "    Uninstalling gym-0.21.0:\n",
      "      Successfully uninstalled gym-0.21.0\n",
      "Successfully installed gym-0.26.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "stable-baselines3 1.6.2 requires gym==0.21, but you have gym 0.26.2 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym[toy_text] in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from gym[toy_text]) (1.22.4)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from gym[toy_text]) (4.13.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from gym[toy_text]) (2.0.0)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from gym[toy_text]) (0.0.8)\n",
      "Requirement already satisfied: pygame==2.1.0 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from gym[toy_text]) (2.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from importlib-metadata>=4.8.0->gym[toy_text]) (3.11.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install swig cmake\n",
    "!pip install -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt\n",
    "!pip install get update\n",
    "!pip install python-opengl\n",
    "!pip install ffmpeg\n",
    "!pip install xvfb\n",
    "!pip3 install pyvirtualdisplay\n",
    "!pip install imageio-ffmpeg\n",
    "!pip install --upgrade gym\n",
    "!pip install gym[toy_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3kuZbWAkfHdg"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DaY1N4dBrabi"
   },
   "outputs": [],
   "source": [
    "# Virtual display\n",
    "#from pyvirtualdisplay import Display\n",
    "\n",
    "#virtual_display = Display(visible=0, size=(1400, 900))\n",
    "#virtual_display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.10\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "VcNvOAQlysBJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniy\\Anaconda3\\envs\\tensorflow25\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Daniy\\Anaconda3\\envs\\tensorflow25\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "C:\\Users\\Daniy\\Anaconda3\\envs\\tensorflow25\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import random\n",
    "import imageio\n",
    "import os\n",
    "import tqdm\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lnrb_nX33fJo"
   },
   "outputs": [],
   "source": [
    "# Let's create our Qtable of size (state_space, action_space) and initialized each values at 0 using np.zeros\n",
    "def initialize_q_table(state_space, action_space):\n",
    "  Qtable = np.zeros((state_space, action_space))\n",
    "  return Qtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "se2OzWGW5kYJ"
   },
   "outputs": [],
   "source": [
    "def greedy_policy(Qtable, state):\n",
    "  # Exploitation: take the action with the highest state, action value\n",
    "  action = np.argmax(Qtable[state][:])\n",
    "  \n",
    "  return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "cYxHuckr4LiG"
   },
   "outputs": [],
   "source": [
    "def epsilon_greedy_policy(Qtable, state, epsilon):\n",
    "  # Randomly generate a number between 0 and 1\n",
    "  random_int = random.uniform(0,1)\n",
    "  # if random_int > greater than epsilon --> exploitation\n",
    "  if random_int > epsilon:\n",
    "    # Take the action with the highest value given a state\n",
    "    # np.argmax can be useful here\n",
    "    action = greedy_policy(Qtable, state)\n",
    "  # else --> exploration\n",
    "  else:\n",
    "    action = env.action_space.sample()\n",
    "  \n",
    "  return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "paOynXy3aoJW"
   },
   "outputs": [],
   "source": [
    "def train(n_training_episodes, min_epsilon, max_epsilon, decay_rate, env, max_steps, Qtable):\n",
    "  for episode in tqdm(range(n_training_episodes)):\n",
    "    # Reduce epsilon (because we need less and less exploration)\n",
    "    epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode)\n",
    "    # Reset the environment\n",
    "    state = env.reset()[0]\n",
    "    step = 0\n",
    "    done = False\n",
    "\n",
    "    # repeat\n",
    "    for step in range(max_steps):\n",
    "      # Choose the action At using epsilon greedy policy\n",
    "      action = epsilon_greedy_policy(Qtable,state,epsilon)\n",
    "\n",
    "      # Take action At and observe Rt+1 and St+1\n",
    "      # Take the action (a) and observe the outcome state(s') and reward (r)\n",
    "      new_state, reward, done,_, info = env.step(action)\n",
    "\n",
    "      # Update Q(s,a):= Q(s,a) + lr [R(s,a) + gamma * max Q(s',a') - Q(s,a)]\n",
    "      Qtable[state][action] = Qtable[state][action] + learning_rate * (reward + gamma * np.max(Qtable[new_state]) - Qtable[state][action])\n",
    "\n",
    "      # If done, finish the episode\n",
    "      if done:\n",
    "        break\n",
    "      \n",
    "      # Our next state is the new state\n",
    "      state = new_state\n",
    "  return Qtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "jNl0_JO2cbkm"
   },
   "outputs": [],
   "source": [
    "def evaluate_agent(env, max_steps, n_eval_episodes, Q, seed):\n",
    "  \"\"\"\n",
    "  Evaluate the agent for ``n_eval_episodes`` episodes and returns average reward and std of reward.\n",
    "  :param env: The evaluation environment\n",
    "  :param n_eval_episodes: Number of episode to evaluate the agent\n",
    "  :param Q: The Q-table\n",
    "  :param seed: The evaluation seed array (for taxi-v3)\n",
    "  \"\"\"\n",
    "  episode_rewards = []\n",
    "  for episode in tqdm(range(n_eval_episodes)):\n",
    "    if seed:\n",
    "      state = env.reset(seed=seed[episode])[0]\n",
    "    else:\n",
    "      state = env.reset()[0]\n",
    "    step = 0\n",
    "    done = False\n",
    "    total_rewards_ep = 0\n",
    "    \n",
    "    for step in range(max_steps):\n",
    "      # Take the action (index) that have the maximum expected future reward given that state\n",
    "      action = greedy_policy(Q, state)\n",
    "      new_state, reward, done,_, info = env.step(action)\n",
    "      total_rewards_ep += reward\n",
    "        \n",
    "      if done:\n",
    "        break\n",
    "      state = new_state\n",
    "    episode_rewards.append(total_rewards_ep)\n",
    "  mean_reward = np.mean(episode_rewards)\n",
    "  std_reward = np.std(episode_rewards)\n",
    "\n",
    "  return mean_reward, std_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Jex3i9lZ8ksX"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi, snapshot_download\n",
    "from huggingface_hub.repocard import metadata_eval_result, metadata_save\n",
    "\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Qo57HBn3W74O"
   },
   "outputs": [],
   "source": [
    "def record_video(env, Qtable, out_directory, fps=1):\n",
    "  \"\"\"\n",
    "  Generate a replay video of the agent\n",
    "  :param env\n",
    "  :param Qtable: Qtable of our agent\n",
    "  :param out_directory\n",
    "  :param fps: how many frame per seconds (with taxi-v3 and frozenlake-v1 we use 1)\n",
    "  \"\"\"\n",
    "  images = []  \n",
    "  done = False\n",
    "  state = env.reset(seed=random.randint(0,500))[0]\n",
    "  img = env.render()\n",
    "  images.append(img)\n",
    "  while not done:\n",
    "    # Take the action (index) that have the maximum expected future reward given that state\n",
    "    action = np.argmax(Qtable[state][:])\n",
    "    state, reward, done,_, info = env.step(action) # We directly put next_state = state for recording logic\n",
    "    img = env.render()\n",
    "    images.append(img)\n",
    "  imageio.mimsave(out_directory, [np.array(img) for i, img in enumerate(images)], fps=fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "U4mdUTKkGnUd"
   },
   "outputs": [],
   "source": [
    "def push_to_hub(\n",
    "    repo_id, model, env, video_fps=1, local_repo_path=\"hub\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Evaluate, Generate a video and Upload a model to Hugging Face Hub.\n",
    "    This method does the complete pipeline:\n",
    "    - It evaluates the model\n",
    "    - It generates the model card\n",
    "    - It generates a replay video of the agent\n",
    "    - It pushes everything to the Hub\n",
    "\n",
    "    :param repo_id: repo_id: id of the model repository from the Hugging Face Hub\n",
    "    :param env\n",
    "    :param video_fps: how many frame per seconds to record our video replay \n",
    "    (with taxi-v3 and frozenlake-v1 we use 1)\n",
    "    :param local_repo_path: where the local repository is\n",
    "    \"\"\"\n",
    "    _, repo_name = repo_id.split(\"/\")\n",
    "\n",
    "    eval_env = env\n",
    "    api = HfApi()\n",
    "\n",
    "    # Step 1: Create the repo\n",
    "    repo_url = api.create_repo(\n",
    "        repo_id=repo_id,\n",
    "        exist_ok=True,\n",
    "    )\n",
    "\n",
    "    # Step 2: Download files\n",
    "    repo_local_path = Path(snapshot_download(repo_id=repo_id))\n",
    "\n",
    "    # Step 3: Save the model\n",
    "    if env.spec.kwargs.get(\"map_name\"):\n",
    "        model[\"map_name\"] = env.spec.kwargs.get(\"map_name\")\n",
    "        if env.spec.kwargs.get(\"is_slippery\", \"\") == False:\n",
    "            model[\"slippery\"] = False\n",
    "\n",
    "    # Pickle the model\n",
    "    with open((repo_local_path) / \"q-learning.pkl\", \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "    # Step 4: Evaluate the model and build JSON with evaluation metrics\n",
    "    mean_reward, std_reward = evaluate_agent(\n",
    "        eval_env, model[\"max_steps\"], model[\"n_eval_episodes\"], model[\"qtable\"], model[\"eval_seed\"]\n",
    "    )\n",
    "\n",
    "    evaluate_data = {\n",
    "        \"env_id\": model[\"env_id\"],\n",
    "        \"mean_reward\": mean_reward,\n",
    "        \"n_eval_episodes\": model[\"n_eval_episodes\"],\n",
    "        \"eval_datetime\": datetime.datetime.now().isoformat()\n",
    "    }\n",
    "\n",
    "    # Write a JSON file called \"results.json\" that will contain the\n",
    "    # evaluation results\n",
    "    with open(repo_local_path / \"results.json\", \"w\") as outfile:\n",
    "        json.dump(evaluate_data, outfile)\n",
    "\n",
    "    # Step 5: Create the model card\n",
    "    env_name = model[\"env_id\"]\n",
    "    if env.spec.kwargs.get(\"map_name\"):\n",
    "        env_name += \"-\" + env.spec.kwargs.get(\"map_name\")\n",
    "\n",
    "    if env.spec.kwargs.get(\"is_slippery\", \"\") == False:\n",
    "        env_name += \"-\" + \"no_slippery\"\n",
    "\n",
    "    metadata = {}\n",
    "    metadata[\"tags\"] = [env_name, \"q-learning\", \"reinforcement-learning\", \"custom-implementation\"]\n",
    "\n",
    "    # Add metrics\n",
    "    eval = metadata_eval_result(\n",
    "        model_pretty_name=repo_name,\n",
    "        task_pretty_name=\"reinforcement-learning\",\n",
    "        task_id=\"reinforcement-learning\",\n",
    "        metrics_pretty_name=\"mean_reward\",\n",
    "        metrics_id=\"mean_reward\",\n",
    "        metrics_value=f\"{mean_reward:.2f} +/- {std_reward:.2f}\",\n",
    "        dataset_pretty_name=env_name,\n",
    "        dataset_id=env_name,\n",
    "    )\n",
    "\n",
    "    # Merges both dictionaries\n",
    "    metadata = {**metadata, **eval}\n",
    "\n",
    "    model_card = f\"\"\"\n",
    "  # **Q-Learning** Agent playing1 **{env_id}**\n",
    "  This is a trained model of a **Q-Learning** agent playing **{env_id}** .\n",
    "\n",
    "  ## Usage\n",
    "\n",
    "  ```python\n",
    "  \n",
    "  model = load_from_hub(repo_id=\"{repo_id}\", filename=\"q-learning.pkl\")\n",
    "\n",
    "  # Don't forget to check if you need to add additional attributes (is_slippery=False etc)\n",
    "  env = gym.make(model[\"env_id\"])\n",
    "  ```\n",
    "  \"\"\"\n",
    "\n",
    "    evaluate_agent(env, model[\"max_steps\"], model[\"n_eval_episodes\"], model[\"qtable\"], model[\"eval_seed\"])\n",
    "  \n",
    "    readme_path = repo_local_path / \"README.md\"\n",
    "    readme = \"\"\n",
    "    print(readme_path.exists())\n",
    "    if readme_path.exists():\n",
    "        with readme_path.open(\"r\", encoding=\"utf8\") as f:\n",
    "            readme = f.read()\n",
    "    else:\n",
    "        readme = model_card\n",
    "\n",
    "    with readme_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(readme)\n",
    "\n",
    "    # Save our metrics to Readme metadata\n",
    "    metadata_save(readme_path, metadata)\n",
    "\n",
    "    # Step 6: Record a video\n",
    "    video_path = repo_local_path / \"replay.mp4\"\n",
    "    record_video(env, model[\"qtable\"], video_path, video_fps)\n",
    "\n",
    "    # Step 7. Push everything to the Hub\n",
    "    api.upload_folder(\n",
    "        repo_id=repo_id,\n",
    "        folder_path=repo_local_path,\n",
    "        path_in_repo=\".\",\n",
    "    )\n",
    "\n",
    "    print(\"Your model is pushed to the Hub. You can view your model here: \", repo_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "QB5nIcxR8paT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid.\n",
      "Your token has been saved in your configured git credential helpers (manager,store).\n",
      "Your token has been saved to C:\\Users\\Daniy\\.huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "gL0wpeO8gpej"
   },
   "outputs": [],
   "source": [
    "env = gym.make(\"Taxi-v3\",render_mode =\"rgb_array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "_TPNaGSZrgqA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  500  possible states\n"
     ]
    }
   ],
   "source": [
    "state_space = env.observation_space.n\n",
    "print(\"There are \", state_space, \" possible states\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "CdeeZuokrhit"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  6  possible actions\n"
     ]
    }
   ],
   "source": [
    "action_space = env.action_space.n\n",
    "print(\"There are \", action_space, \" possible actions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "US3yDXnEtY9I"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "Q-table shape:  (500, 6)\n"
     ]
    }
   ],
   "source": [
    "# Create our Q table with state_size rows and action_size columns (500x6)\n",
    "Qtable_taxi = initialize_q_table(state_space, action_space)\n",
    "print(Qtable_taxi)\n",
    "print(\"Q-table shape: \", Qtable_taxi .shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "AB6n__hhg7YS"
   },
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "n_training_episodes = 25000   # Total training episodes\n",
    "learning_rate = 0.7           # Learning rate\n",
    "\n",
    "# Evaluation parameters\n",
    "n_eval_episodes = 100        # Total number of test episodes\n",
    "\n",
    "# DO NOT MODIFY EVAL_SEED\n",
    "eval_seed = [16,54,165,177,191,191,120,80,149,178,48,38,6,125,174,73,50,172,100,148,146,6,25,40,68,148,49,167,9,97,164,176,61,7,54,55,\n",
    " 161,131,184,51,170,12,120,113,95,126,51,98,36,135,54,82,45,95,89,59,95,124,9,113,58,85,51,134,121,169,105,21,30,11,50,65,12,43,82,145,152,97,106,55,31,85,38,\n",
    " 112,102,168,123,97,21,83,158,26,80,63,5,81,32,11,28,148] # Evaluation seed, this ensures that all classmates agents are trained on the same taxi starting position\n",
    "                                                          # Each seed has a specific starting state\n",
    "\n",
    "# Environment parameters\n",
    "env_id = \"Taxi-v3\"           # Name of the environment\n",
    "max_steps = 99               # Max steps per episode\n",
    "gamma = 0.95                 # Discounting rate\n",
    "\n",
    "# Exploration parameters\n",
    "max_epsilon = 1.0             # Exploration probability at start\n",
    "min_epsilon = 0.05           # Minimum exploration probability \n",
    "decay_rate = 0.005            # Exponential decay rate for exploration prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "WwP3Y2z2eS-K"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93e17b06c0454e1199dc384578f0f12a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  2.75200369,   3.94946999,   2.75200369,   3.94947744,\n",
       "          5.20997639,  -5.05052243],\n",
       "       [  7.93349184,   9.40367562,   7.93349184,   9.40367562,\n",
       "         10.9512375 ,   0.40367562],\n",
       "       ...,\n",
       "       [ -3.04895836,  12.57994507,  -2.90172656,  -2.98315298,\n",
       "        -11.0152525 , -10.9009005 ],\n",
       "       [ -4.85838716,  -5.01076879,  -4.73873105,   6.53681725,\n",
       "        -11.54672896, -13.58392376],\n",
       "       [ 10.997     ,  -0.91      ,  11.06      ,  18.        ,\n",
       "          0.        ,   4.4080085 ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Qtable_taxi = train(n_training_episodes, min_epsilon, max_epsilon, decay_rate, env, max_steps, Qtable_taxi)\n",
    "Qtable_taxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9eb781991fb4d9ca0005723e50b6f9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_reward=7.46 +/- 2.74\n"
     ]
    }
   ],
   "source": [
    "# Evaluate our Agent\n",
    "mean_reward, std_reward = evaluate_agent(env, max_steps, n_eval_episodes, Qtable_taxi, eval_seed)\n",
    "print(f\"Mean_reward={mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "0a1FpE_3hNYr"
   },
   "outputs": [],
   "source": [
    "model = {\n",
    "    \"env_id\": env_id,\n",
    "    \"max_steps\": max_steps,\n",
    "    \"n_training_episodes\": n_training_episodes,\n",
    "    \"n_eval_episodes\": n_eval_episodes,\n",
    "    \"eval_seed\": eval_seed,\n",
    "\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"gamma\": gamma,\n",
    "\n",
    "    \"max_epsilon\": max_epsilon,\n",
    "    \"min_epsilon\": min_epsilon,\n",
    "    \"decay_rate\": decay_rate,\n",
    "\n",
    "    \"qtable\": Qtable_taxi\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'env_id': 'Taxi-v3',\n",
       " 'max_steps': 99,\n",
       " 'n_training_episodes': 25000,\n",
       " 'n_eval_episodes': 100,\n",
       " 'eval_seed': [16,\n",
       "  54,\n",
       "  165,\n",
       "  177,\n",
       "  191,\n",
       "  191,\n",
       "  120,\n",
       "  80,\n",
       "  149,\n",
       "  178,\n",
       "  48,\n",
       "  38,\n",
       "  6,\n",
       "  125,\n",
       "  174,\n",
       "  73,\n",
       "  50,\n",
       "  172,\n",
       "  100,\n",
       "  148,\n",
       "  146,\n",
       "  6,\n",
       "  25,\n",
       "  40,\n",
       "  68,\n",
       "  148,\n",
       "  49,\n",
       "  167,\n",
       "  9,\n",
       "  97,\n",
       "  164,\n",
       "  176,\n",
       "  61,\n",
       "  7,\n",
       "  54,\n",
       "  55,\n",
       "  161,\n",
       "  131,\n",
       "  184,\n",
       "  51,\n",
       "  170,\n",
       "  12,\n",
       "  120,\n",
       "  113,\n",
       "  95,\n",
       "  126,\n",
       "  51,\n",
       "  98,\n",
       "  36,\n",
       "  135,\n",
       "  54,\n",
       "  82,\n",
       "  45,\n",
       "  95,\n",
       "  89,\n",
       "  59,\n",
       "  95,\n",
       "  124,\n",
       "  9,\n",
       "  113,\n",
       "  58,\n",
       "  85,\n",
       "  51,\n",
       "  134,\n",
       "  121,\n",
       "  169,\n",
       "  105,\n",
       "  21,\n",
       "  30,\n",
       "  11,\n",
       "  50,\n",
       "  65,\n",
       "  12,\n",
       "  43,\n",
       "  82,\n",
       "  145,\n",
       "  152,\n",
       "  97,\n",
       "  106,\n",
       "  55,\n",
       "  31,\n",
       "  85,\n",
       "  38,\n",
       "  112,\n",
       "  102,\n",
       "  168,\n",
       "  123,\n",
       "  97,\n",
       "  21,\n",
       "  83,\n",
       "  158,\n",
       "  26,\n",
       "  80,\n",
       "  63,\n",
       "  5,\n",
       "  81,\n",
       "  32,\n",
       "  11,\n",
       "  28,\n",
       "  148],\n",
       " 'learning_rate': 0.7,\n",
       " 'gamma': 0.95,\n",
       " 'max_epsilon': 1.0,\n",
       " 'min_epsilon': 0.05,\n",
       " 'decay_rate': 0.005,\n",
       " 'qtable': array([[  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "           0.        ,   0.        ],\n",
       "        [  2.75200369,   3.94946999,   2.75200369,   3.94947744,\n",
       "           5.20997639,  -5.05052243],\n",
       "        [  7.93349184,   9.40367562,   7.93349184,   9.40367562,\n",
       "          10.9512375 ,   0.40367562],\n",
       "        ...,\n",
       "        [ -3.04895836,  12.57994507,  -2.90172656,  -2.98315298,\n",
       "         -11.0152525 , -10.9009005 ],\n",
       "        [ -4.85838716,  -5.01076879,  -4.73873105,   6.53681725,\n",
       "         -11.54672896, -13.58392376],\n",
       "        [ 10.997     ,  -0.91      ,  11.06      ,  18.        ,\n",
       "           0.        ,   4.4080085 ]])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "dhQtiQozhOn1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac094e6a89a04300b2bbec5941b6c586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4191b0f329af49678c6a890703505c48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dfc6544683d45ca99fbf602db247cfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (550, 350) to (560, 352) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your model is pushed to the Hub. You can view your model here:  https://huggingface.co/AxlDM124/Taxi-v3\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "username = \"AxlDM124\" \n",
    "repo_name = \"Taxi-v3\"\n",
    "push_to_hub(\n",
    "    repo_id=f\"{username}/{repo_name}\",\n",
    "    model=model,\n",
    "    env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Ji_UrI5l2zzn",
    "67OdoKL63eDD",
    "B2_-8b8z5k54"
   ],
   "private_outputs": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
