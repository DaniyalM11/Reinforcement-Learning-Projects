{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frozen Lake\n",
    "### by Daniyal Mufti\n",
    "### Based on Hugging Face Course on Deep Reinforcement Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9XaULfDZDvrC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gym==0.24\n",
      "  Downloading gym-0.24.0.tar.gz (694 kB)\n",
      "     ------------------------------------- 694.4/694.4 kB 14.6 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting pygame\n",
      "  Downloading pygame-2.1.2-cp38-cp38-win_amd64.whl (8.4 MB)\n",
      "     ---------------------------------------- 8.4/8.4 MB 30.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit2/requirements-unit2.txt (line 3)) (1.22.4)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit2/requirements-unit2.txt (line 5)) (0.11.1)\n",
      "Collecting pickle5\n",
      "  Downloading pickle5-0.0.11.tar.gz (132 kB)\n",
      "     ---------------------------------------- 132.1/132.1 kB ? eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: pyyaml==6.0 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit2/requirements-unit2.txt (line 7)) (6.0)\n",
      "Requirement already satisfied: imageio in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit2/requirements-unit2.txt (line 8)) (2.19.3)\n",
      "Requirement already satisfied: imageio_ffmpeg in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit2/requirements-unit2.txt (line 9)) (0.4.7)\n",
      "Requirement already satisfied: pyglet==1.5.1 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit2/requirements-unit2.txt (line 10)) (1.5.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit2/requirements-unit2.txt (line 11)) (4.62.3)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from gym==0.24->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit2/requirements-unit2.txt (line 1)) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from gym==0.24->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit2/requirements-unit2.txt (line 1)) (4.13.0)\n",
      "Collecting gym-notices>=0.0.4\n",
      "  Downloading gym_notices-0.0.8-py3-none-any.whl (3.0 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from huggingface_hub->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit2/requirements-unit2.txt (line 5)) (2.28.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from huggingface_hub->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit2/requirements-unit2.txt (line 5)) (22.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from huggingface_hub->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit2/requirements-unit2.txt (line 5)) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from huggingface_hub->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit2/requirements-unit2.txt (line 5)) (4.4.0)\n",
      "Requirement already satisfied: pillow>=8.3.2 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from imageio->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit2/requirements-unit2.txt (line 8)) (9.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from tqdm->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit2/requirements-unit2.txt (line 11)) (0.4.6)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from importlib-metadata>=4.8.0->gym==0.24->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit2/requirements-unit2.txt (line 1)) (3.11.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from requests->huggingface_hub->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit2/requirements-unit2.txt (line 5)) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from requests->huggingface_hub->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit2/requirements-unit2.txt (line 5)) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from requests->huggingface_hub->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit2/requirements-unit2.txt (line 5)) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from requests->huggingface_hub->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit2/requirements-unit2.txt (line 5)) (2022.12.7)\n",
      "Building wheels for collected packages: gym, pickle5\n",
      "  Building wheel for gym (pyproject.toml): started\n",
      "  Building wheel for gym (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for gym: filename=gym-0.24.0-py3-none-any.whl size=790693 sha256=9b92fed31ce9fd778917127e2ca6f14f4329441fa0b9a4fa34474f3971de526c\n",
      "  Stored in directory: c:\\users\\daniy\\appdata\\local\\pip\\cache\\wheels\\ab\\72\\b1\\94bb0cf64930d3e5e82ff91c7af6cd92c251f19a69943c06ff\n",
      "  Building wheel for pickle5 (setup.py): started\n",
      "  Building wheel for pickle5 (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for pickle5\n",
      "Successfully built gym\n",
      "Failed to build pickle5\n",
      "Installing collected packages: pickle5, gym-notices, pygame, gym\n",
      "  Running setup.py install for pickle5: started\n",
      "  Running setup.py install for pickle5: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py bdist_wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [38 lines of output]\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-38\n",
      "  creating build\\lib.win-amd64-cpython-38\\pickle5\n",
      "  copying pickle5\\pickle.py -> build\\lib.win-amd64-cpython-38\\pickle5\n",
      "  copying pickle5\\pickletools.py -> build\\lib.win-amd64-cpython-38\\pickle5\n",
      "  copying pickle5\\__init__.py -> build\\lib.win-amd64-cpython-38\\pickle5\n",
      "  creating build\\lib.win-amd64-cpython-38\\pickle5\\test\n",
      "  copying pickle5\\test\\pickletester.py -> build\\lib.win-amd64-cpython-38\\pickle5\\test\n",
      "  copying pickle5\\test\\test_pickle.py -> build\\lib.win-amd64-cpython-38\\pickle5\\test\n",
      "  copying pickle5\\test\\test_picklebuffer.py -> build\\lib.win-amd64-cpython-38\\pickle5\\test\n",
      "  copying pickle5\\test\\__init__.py -> build\\lib.win-amd64-cpython-38\\pickle5\\test\n",
      "  running build_ext\n",
      "  building 'pickle5._pickle' extension\n",
      "  creating build\\temp.win-amd64-cpython-38\n",
      "  creating build\\temp.win-amd64-cpython-38\\Release\n",
      "  creating build\\temp.win-amd64-cpython-38\\Release\\pickle5\n",
      "  \"C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.31.31103\\bin\\HostX86\\x64\\cl.exe\" /c /nologo /O2 /W3 /GL /DNDEBUG /MD -IC:\\Users\\Daniy\\Anaconda3\\envs\\tensorflow25\\include -IC:\\Users\\Daniy\\Anaconda3\\envs\\tensorflow25\\Include \"-IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.31.31103\\ATLMFC\\include\" \"-IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.31.31103\\include\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\winrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\cppwinrt\" /Tcpickle5/_pickle.c /Fobuild\\temp.win-amd64-cpython-38\\Release\\pickle5/_pickle.obj\n",
      "  _pickle.c\n",
      "  \"C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.31.31103\\bin\\HostX86\\x64\\cl.exe\" /c /nologo /O2 /W3 /GL /DNDEBUG /MD -IC:\\Users\\Daniy\\Anaconda3\\envs\\tensorflow25\\include -IC:\\Users\\Daniy\\Anaconda3\\envs\\tensorflow25\\Include \"-IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.31.31103\\ATLMFC\\include\" \"-IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.31.31103\\include\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\winrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\cppwinrt\" /Tcpickle5/picklebufobject.c /Fobuild\\temp.win-amd64-cpython-38\\Release\\pickle5/picklebufobject.obj\n",
      "  picklebufobject.c\n",
      "  pickle5/picklebufobject.c(19): warning C4273: 'PyPickleBuffer_FromObject': inconsistent dll linkage\n",
      "  C:\\Users\\Daniy\\Anaconda3\\envs\\tensorflow25\\include\\picklebufobject.h(18): note: see previous definition of 'PyPickleBuffer_FromObject'\n",
      "  pickle5/picklebufobject.c(38): warning C4273: 'PyPickleBuffer_GetBuffer': inconsistent dll linkage\n",
      "  C:\\Users\\Daniy\\Anaconda3\\envs\\tensorflow25\\include\\picklebufobject.h(22): note: see previous definition of 'PyPickleBuffer_GetBuffer'\n",
      "  pickle5/picklebufobject.c(57): warning C4273: 'PyPickleBuffer_Release': inconsistent dll linkage\n",
      "  C:\\Users\\Daniy\\Anaconda3\\envs\\tensorflow25\\include\\picklebufobject.h(24): note: see previous definition of 'PyPickleBuffer_Release'\n",
      "  pickle5/picklebufobject.c(208): warning C4273: 'PyPickleBuffer_Type': inconsistent dll linkage\n",
      "  C:\\Users\\Daniy\\Anaconda3\\envs\\tensorflow25\\include\\picklebufobject.h(13): note: see previous definition of 'PyPickleBuffer_Type'\n",
      "  \"C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.31.31103\\bin\\HostX86\\x64\\link.exe\" /nologo /INCREMENTAL:NO /LTCG /DLL /MANIFEST:EMBED,ID=2 /MANIFESTUAC:NO /LIBPATH:C:\\Users\\Daniy\\Anaconda3\\envs\\tensorflow25\\libs /LIBPATH:C:\\Users\\Daniy\\Anaconda3\\envs\\tensorflow25 /LIBPATH:C:\\Users\\Daniy\\Anaconda3\\envs\\tensorflow25\\PCbuild\\amd64 \"/LIBPATH:C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.31.31103\\ATLMFC\\lib\\x64\" \"/LIBPATH:C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.31.31103\\lib\\x64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.19041.0\\ucrt\\x64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\\\lib\\10.0.19041.0\\\\um\\x64\" /EXPORT:PyInit__pickle build\\temp.win-amd64-cpython-38\\Release\\pickle5/_pickle.obj build\\temp.win-amd64-cpython-38\\Release\\pickle5/picklebufobject.obj /OUT:build\\lib.win-amd64-cpython-38\\pickle5\\_pickle.cp38-win_amd64.pyd /IMPLIB:build\\temp.win-amd64-cpython-38\\Release\\pickle5\\_pickle.cp38-win_amd64.lib\n",
      "     Creating library build\\temp.win-amd64-cpython-38\\Release\\pickle5\\_pickle.cp38-win_amd64.lib and object build\\temp.win-amd64-cpython-38\\Release\\pickle5\\_pickle.cp38-win_amd64.exp\n",
      "  Generating code\n",
      "  Finished generating code\n",
      "  picklebufobject.obj : error LNK2005: PyPickleBuffer_GetBuffer already defined in python38.lib(python38.dll)\n",
      "  build\\lib.win-amd64-cpython-38\\pickle5\\_pickle.cp38-win_amd64.pyd : fatal error LNK1169: one or more multiply defined symbols found\n",
      "  error: command 'C:\\\\Program Files\\\\Microsoft Visual Studio\\\\2022\\\\Community\\\\VC\\\\Tools\\\\MSVC\\\\14.31.31103\\\\bin\\\\HostX86\\\\x64\\\\link.exe' failed with exit code 1169\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for pickle5\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Running setup.py install for pickle5 did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [40 lines of output]\n",
      "  running install\n",
      "  C:\\Users\\Daniy\\Anaconda3\\envs\\tensorflow25\\lib\\site-packages\\setuptools\\command\\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "    warnings.warn(\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-38\n",
      "  creating build\\lib.win-amd64-cpython-38\\pickle5\n",
      "  copying pickle5\\pickle.py -> build\\lib.win-amd64-cpython-38\\pickle5\n",
      "  copying pickle5\\pickletools.py -> build\\lib.win-amd64-cpython-38\\pickle5\n",
      "  copying pickle5\\__init__.py -> build\\lib.win-amd64-cpython-38\\pickle5\n",
      "  creating build\\lib.win-amd64-cpython-38\\pickle5\\test\n",
      "  copying pickle5\\test\\pickletester.py -> build\\lib.win-amd64-cpython-38\\pickle5\\test\n",
      "  copying pickle5\\test\\test_pickle.py -> build\\lib.win-amd64-cpython-38\\pickle5\\test\n",
      "  copying pickle5\\test\\test_picklebuffer.py -> build\\lib.win-amd64-cpython-38\\pickle5\\test\n",
      "  copying pickle5\\test\\__init__.py -> build\\lib.win-amd64-cpython-38\\pickle5\\test\n",
      "  running build_ext\n",
      "  building 'pickle5._pickle' extension\n",
      "  creating build\\temp.win-amd64-cpython-38\n",
      "  creating build\\temp.win-amd64-cpython-38\\Release\n",
      "  creating build\\temp.win-amd64-cpython-38\\Release\\pickle5\n",
      "  \"C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.31.31103\\bin\\HostX86\\x64\\cl.exe\" /c /nologo /O2 /W3 /GL /DNDEBUG /MD -IC:\\Users\\Daniy\\Anaconda3\\envs\\tensorflow25\\include -IC:\\Users\\Daniy\\Anaconda3\\envs\\tensorflow25\\Include \"-IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.31.31103\\ATLMFC\\include\" \"-IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.31.31103\\include\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\winrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\cppwinrt\" /Tcpickle5/_pickle.c /Fobuild\\temp.win-amd64-cpython-38\\Release\\pickle5/_pickle.obj\n",
      "  _pickle.c\n",
      "  \"C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.31.31103\\bin\\HostX86\\x64\\cl.exe\" /c /nologo /O2 /W3 /GL /DNDEBUG /MD -IC:\\Users\\Daniy\\Anaconda3\\envs\\tensorflow25\\include -IC:\\Users\\Daniy\\Anaconda3\\envs\\tensorflow25\\Include \"-IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.31.31103\\ATLMFC\\include\" \"-IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.31.31103\\include\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\winrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.19041.0\\\\cppwinrt\" /Tcpickle5/picklebufobject.c /Fobuild\\temp.win-amd64-cpython-38\\Release\\pickle5/picklebufobject.obj\n",
      "  picklebufobject.c\n",
      "  pickle5/picklebufobject.c(19): warning C4273: 'PyPickleBuffer_FromObject': inconsistent dll linkage\n",
      "  C:\\Users\\Daniy\\Anaconda3\\envs\\tensorflow25\\include\\picklebufobject.h(18): note: see previous definition of 'PyPickleBuffer_FromObject'\n",
      "  pickle5/picklebufobject.c(38): warning C4273: 'PyPickleBuffer_GetBuffer': inconsistent dll linkage\n",
      "  C:\\Users\\Daniy\\Anaconda3\\envs\\tensorflow25\\include\\picklebufobject.h(22): note: see previous definition of 'PyPickleBuffer_GetBuffer'\n",
      "  pickle5/picklebufobject.c(57): warning C4273: 'PyPickleBuffer_Release': inconsistent dll linkage\n",
      "  C:\\Users\\Daniy\\Anaconda3\\envs\\tensorflow25\\include\\picklebufobject.h(24): note: see previous definition of 'PyPickleBuffer_Release'\n",
      "  pickle5/picklebufobject.c(208): warning C4273: 'PyPickleBuffer_Type': inconsistent dll linkage\n",
      "  C:\\Users\\Daniy\\Anaconda3\\envs\\tensorflow25\\include\\picklebufobject.h(13): note: see previous definition of 'PyPickleBuffer_Type'\n",
      "  \"C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.31.31103\\bin\\HostX86\\x64\\link.exe\" /nologo /INCREMENTAL:NO /LTCG /DLL /MANIFEST:EMBED,ID=2 /MANIFESTUAC:NO /LIBPATH:C:\\Users\\Daniy\\Anaconda3\\envs\\tensorflow25\\libs /LIBPATH:C:\\Users\\Daniy\\Anaconda3\\envs\\tensorflow25 /LIBPATH:C:\\Users\\Daniy\\Anaconda3\\envs\\tensorflow25\\PCbuild\\amd64 \"/LIBPATH:C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.31.31103\\ATLMFC\\lib\\x64\" \"/LIBPATH:C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.31.31103\\lib\\x64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.19041.0\\ucrt\\x64\" \"/LIBPATH:C:\\Program Files (x86)\\Windows Kits\\10\\\\lib\\10.0.19041.0\\\\um\\x64\" /EXPORT:PyInit__pickle build\\temp.win-amd64-cpython-38\\Release\\pickle5/_pickle.obj build\\temp.win-amd64-cpython-38\\Release\\pickle5/picklebufobject.obj /OUT:build\\lib.win-amd64-cpython-38\\pickle5\\_pickle.cp38-win_amd64.pyd /IMPLIB:build\\temp.win-amd64-cpython-38\\Release\\pickle5\\_pickle.cp38-win_amd64.lib\n",
      "     Creating library build\\temp.win-amd64-cpython-38\\Release\\pickle5\\_pickle.cp38-win_amd64.lib and object build\\temp.win-amd64-cpython-38\\Release\\pickle5\\_pickle.cp38-win_amd64.exp\n",
      "  Generating code\n",
      "  Finished generating code\n",
      "  picklebufobject.obj : error LNK2005: PyPickleBuffer_GetBuffer already defined in python38.lib(python38.dll)\n",
      "  build\\lib.win-amd64-cpython-38\\pickle5\\_pickle.cp38-win_amd64.pyd : fatal error LNK1169: one or more multiply defined symbols found\n",
      "  error: command 'C:\\\\Program Files\\\\Microsoft Visual Studio\\\\2022\\\\Community\\\\VC\\\\Tools\\\\MSVC\\\\14.31.31103\\\\bin\\\\HostX86\\\\x64\\\\link.exe' failed with exit code 1169\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: legacy-install-failure\n",
      "\n",
      "Encountered error while trying to install package.\n",
      "\n",
      "pickle5\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for output from the failure.\n"
     ]
    }
   ],
   "source": [
    "!pip install -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit2/requirements-unit2.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "n71uTX7qqzz2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: swig in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (4.1.1)\n",
      "Requirement already satisfied: cmake in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (3.25.0)\n",
      "Requirement already satisfied: stable-baselines3[extra] in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (1.6.2)\n",
      "Requirement already satisfied: box2d in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 2)) (2.3.10)\n",
      "Requirement already satisfied: box2d-kengz in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 3)) (2.3.3)\n",
      "Requirement already satisfied: huggingface_sb3 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 4)) (2.2.4)\n",
      "Requirement already satisfied: pyglet==1.5.1 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 5)) (1.5.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (3.3.4)\n",
      "Requirement already satisfied: importlib-metadata~=4.13 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (4.13.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (1.22.4)\n",
      "Collecting gym==0.21\n",
      "  Using cached gym-0.21.0-py3-none-any.whl\n",
      "Requirement already satisfied: pandas in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (2.0.0)\n",
      "Requirement already satisfied: torch>=1.11 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (1.13.1)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (4.7.0.68)\n",
      "Requirement already satisfied: autorom[accept-rom-license]~=0.4.2 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (0.4.2)\n",
      "Requirement already satisfied: tensorboard>=2.9.1 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (2.10.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (9.2.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (4.62.3)\n",
      "Requirement already satisfied: psutil in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (5.9.0)\n",
      "Requirement already satisfied: rich in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (13.0.1)\n",
      "Requirement already satisfied: ale-py==0.7.4 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (0.7.4)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from ale-py==0.7.4->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (5.4.0)\n",
      "Requirement already satisfied: huggingface-hub~=0.8 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from huggingface_sb3->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 4)) (0.11.1)\n",
      "Requirement already satisfied: wasabi in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from huggingface_sb3->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 4)) (1.1.0)\n",
      "Requirement already satisfied: pyyaml~=6.0 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from huggingface_sb3->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 4)) (6.0)\n",
      "Requirement already satisfied: click in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (8.0.4)\n",
      "Requirement already satisfied: requests in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (2.28.1)\n",
      "Requirement already satisfied: AutoROM.accept-rom-license in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (0.5.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from huggingface-hub~=0.8->huggingface_sb3->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 4)) (3.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from huggingface-hub~=0.8->huggingface_sb3->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 4)) (22.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from huggingface-hub~=0.8->huggingface_sb3->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 4)) (4.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from importlib-metadata~=4.13->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (3.11.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (3.19.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (3.4.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (2.15.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (2.2.2)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (0.38.4)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (0.4.6)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (1.51.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (65.6.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (0.6.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from matplotlib->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from matplotlib->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from matplotlib->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from matplotlib->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (0.11.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from pandas->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (2022.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from rich->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (2.11.2)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from rich->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (0.9.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from tqdm->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (0.4.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (0.2.8)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (5.2.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (3.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (2.1.1)\n",
      "Requirement already satisfied: libtorrent in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from AutoROM.accept-rom-license->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (2.0.7)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->stable-baselines3[extra]->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (3.2.2)\n",
      "Installing collected packages: gym\n",
      "  Attempting uninstall: gym\n",
      "    Found existing installation: gym 0.26.2\n",
      "    Uninstalling gym-0.26.2:\n",
      "      Successfully uninstalled gym-0.26.2\n",
      "Successfully installed gym-0.21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement get (from versions: none)\n",
      "ERROR: No matching distribution found for get\n",
      "ERROR: Could not find a version that satisfies the requirement python-opengl (from versions: none)\n",
      "ERROR: No matching distribution found for python-opengl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ffmpeg in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (1.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement xvfb (from versions: none)\n",
      "ERROR: No matching distribution found for xvfb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyvirtualdisplay in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (3.0)\n",
      "Requirement already satisfied: imageio-ffmpeg in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (0.4.7)\n",
      "Requirement already satisfied: gym in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (0.21.0)\n",
      "Collecting gym\n",
      "  Using cached gym-0.26.2-py3-none-any.whl\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from gym) (4.13.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from gym) (1.22.4)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from gym) (0.0.8)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from gym) (2.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from importlib-metadata>=4.8.0->gym) (3.11.0)\n",
      "Installing collected packages: gym\n",
      "  Attempting uninstall: gym\n",
      "    Found existing installation: gym 0.21.0\n",
      "    Uninstalling gym-0.21.0:\n",
      "      Successfully uninstalled gym-0.21.0\n",
      "Successfully installed gym-0.26.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "stable-baselines3 1.6.2 requires gym==0.21, but you have gym 0.26.2 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym[toy_text] in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (0.26.2)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from gym[toy_text]) (4.13.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from gym[toy_text]) (2.0.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from gym[toy_text]) (1.22.4)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from gym[toy_text]) (0.0.8)\n",
      "Collecting pygame==2.1.0\n",
      "  Downloading pygame-2.1.0-cp38-cp38-win_amd64.whl (4.8 MB)\n",
      "     ---------------------------------------- 4.8/4.8 MB 9.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\daniy\\anaconda3\\envs\\tensorflow25\\lib\\site-packages (from importlib-metadata>=4.8.0->gym[toy_text]) (3.11.0)\n",
      "Installing collected packages: pygame\n",
      "Successfully installed pygame-2.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install swig cmake\n",
    "!pip install -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt\n",
    "!pip install get update\n",
    "!pip install python-opengl\n",
    "!pip install ffmpeg\n",
    "!pip install xvfb\n",
    "!pip3 install pyvirtualdisplay\n",
    "!pip install imageio-ffmpeg\n",
    "!pip install --upgrade gym\n",
    "!pip install gym[toy_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3kuZbWAkfHdg"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "DaY1N4dBrabi"
   },
   "outputs": [],
   "source": [
    "# Virtual display\n",
    "#from pyvirtualdisplay import Display\n",
    "\n",
    "#virtual_display = Display(visible=0, size=(1400, 900))\n",
    "#virtual_display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.10\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "VcNvOAQlysBJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniy\\Anaconda3\\envs\\tensorflow25\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Daniy\\Anaconda3\\envs\\tensorflow25\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "C:\\Users\\Daniy\\Anaconda3\\envs\\tensorflow25\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import random\n",
    "import imageio\n",
    "import os\n",
    "import tqdm\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "IzJnb8O3y8up"
   },
   "outputs": [],
   "source": [
    "env = gym.make(\"FrozenLake-v1\",render_mode =\"rgb_array\", map_name=\"4x4\", is_slippery=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SXbTfdeJ1Xi9"
   },
   "source": [
    "### Let's see what the Environment looks like:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ZNPG0g_UGCfh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____OBSERVATION SPACE_____ \n",
      "\n",
      "Observation Space Discrete(16)\n",
      "Sample observation 14\n"
     ]
    }
   ],
   "source": [
    "# We create our environment with gym.make(\"<name_of_the_environment>\")- `is_slippery=False`: The agent always moves in the intended direction due to the non-slippery nature of the frozen lake (deterministic).\n",
    "print(\"_____OBSERVATION SPACE_____ \\n\")\n",
    "print(\"Observation Space\", env.observation_space)\n",
    "print(\"Sample observation\", env.observation_space.sample()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "We5WqOBGLoSm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " _____ACTION SPACE_____ \n",
      "\n",
      "Action Space Shape 4\n",
      "Action Space Sample 2\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n _____ACTION SPACE_____ \\n\")\n",
    "print(\"Action Space Shape\", env.action_space.n)\n",
    "print(\"Action Space Sample\", env.action_space.sample()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "y3ZCdluj3k0l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  16  possible states\n",
      "There are  4  possible actions\n"
     ]
    }
   ],
   "source": [
    "state_space = env.observation_space.n\n",
    "print(\"There are \", state_space, \" possible states\")\n",
    "\n",
    "action_space = env.action_space.n\n",
    "print(\"There are \", action_space, \" possible actions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "rCddoOXM3UQH"
   },
   "outputs": [],
   "source": [
    "# Let's create our Qtable of size (state_space, action_space) and initialized each values at 0 using np.zeros\n",
    "def initialize_q_table(state_space, action_space):\n",
    "  Qtable = np.zeros((state_space, action_space))\n",
    "  return Qtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "9YfvrqRt3jdR"
   },
   "outputs": [],
   "source": [
    "Qtable_frozenlake = initialize_q_table(state_space, action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "E3SCLmLX5bWG"
   },
   "outputs": [],
   "source": [
    "def greedy_policy(Qtable, state):\n",
    "  # Exploitation: take the action with the highest state, action value\n",
    "  action = np.argmax(Qtable[state][:])\n",
    "  \n",
    "  return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "6Bj7x3in3_Pq"
   },
   "outputs": [],
   "source": [
    "def epsilon_greedy_policy(Qtable, state, epsilon):\n",
    "  # Randomly generate a number between 0 and 1\n",
    "  random_num = random.uniform(0, 1)\n",
    "  # if random_num > greater than epsilon --> exploitation\n",
    "  if random_num > epsilon:\n",
    "    # Take the action with the highest value given a state\n",
    "    # np.argmax can be useful here\n",
    "    action = greedy_policy(Qtable, state)\n",
    "  # else --> exploration\n",
    "  else:\n",
    "    action = env.action_space.sample()\n",
    "  \n",
    "  return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Y1tWn0tycWZ1"
   },
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "n_training_episodes = 10000  # Total training episodes\n",
    "learning_rate = 0.7          # Learning rate\n",
    "\n",
    "# Evaluation parameters\n",
    "n_eval_episodes = 100        # Total number of test episodes\n",
    "\n",
    "# Environment parameters\n",
    "env_id = \"FrozenLake-v1\"     # Name of the environment\n",
    "max_steps = 99               # Max steps per episode\n",
    "gamma = 0.95                 # Discounting rate\n",
    "eval_seed = []               # The evaluation seed of the environment\n",
    "\n",
    "# Exploration parameters\n",
    "max_epsilon = 1.0             # Exploration probability at start\n",
    "min_epsilon = 0.05            # Minimum exploration probability \n",
    "decay_rate = 0.0005            # Exponential decay rate for exploration prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(env.reset()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "paOynXy3aoJW"
   },
   "outputs": [],
   "source": [
    "def train(n_training_episodes, min_epsilon, max_epsilon, decay_rate, env, max_steps, Qtable):\n",
    "  for episode in tqdm(range(n_training_episodes)):\n",
    "    # Reduce epsilon (because we need less and less exploration)\n",
    "    epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode)\n",
    "    # Reset the environment\n",
    "    state = env.reset()[0]\n",
    "    step = 0\n",
    "    done = False\n",
    "\n",
    "    # repeat\n",
    "    for step in range(max_steps):\n",
    "      # Choose the action At using epsilon greedy policy\n",
    "      action = epsilon_greedy_policy(Qtable,state,epsilon)\n",
    "\n",
    "      # Take action At and observe Rt+1 and St+1\n",
    "      # Take the action (a) and observe the outcome state(s') and reward (r)\n",
    "      new_state, reward, done,_, info = env.step(action)\n",
    "\n",
    "      # Update Q(s,a):= Q(s,a) + lr [R(s,a) + gamma * max Q(s',a') - Q(s,a)]\n",
    "      Qtable[state][action] = Qtable[state][action] + learning_rate * (reward + gamma * np.max(Qtable[new_state]) - Qtable[state][action])\n",
    "\n",
    "      # If done, finish the episode\n",
    "      if done:\n",
    "        break\n",
    "      \n",
    "      # Our next state is the new state\n",
    "      state = new_state\n",
    "  return Qtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "DPBxfjJdTCOH"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dcb2aff2f8e4d2c994afab33d0b356b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Qtable_frozenlake = train(n_training_episodes, min_epsilon, max_epsilon, decay_rate, env, max_steps, Qtable_frozenlake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "nmfchsTITw4q"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.73509189, 0.77378094, 0.77378094, 0.73509189],\n",
       "       [0.73509189, 0.        , 0.81450625, 0.77378094],\n",
       "       [0.77378094, 0.857375  , 0.77378094, 0.81450625],\n",
       "       [0.81450625, 0.        , 0.77378094, 0.77378094],\n",
       "       [0.77378094, 0.81450625, 0.        , 0.73509189],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.9025    , 0.        , 0.81450625],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.81450625, 0.        , 0.857375  , 0.77378094],\n",
       "       [0.81450625, 0.9025    , 0.9025    , 0.        ],\n",
       "       [0.857375  , 0.95      , 0.        , 0.857375  ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.9025    , 0.95      , 0.857375  ],\n",
       "       [0.9025    , 0.95      , 1.        , 0.9025    ],\n",
       "       [0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Qtable_frozenlake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "jNl0_JO2cbkm"
   },
   "outputs": [],
   "source": [
    "def evaluate_agent(env, max_steps, n_eval_episodes, Q, seed):\n",
    "  \"\"\"\n",
    "  Evaluate the agent for ``n_eval_episodes`` episodes and returns average reward and std of reward.\n",
    "  :param env: The evaluation environment\n",
    "  :param n_eval_episodes: Number of episode to evaluate the agent\n",
    "  :param Q: The Q-table\n",
    "  :param seed: The evaluation seed array (for taxi-v3)\n",
    "  \"\"\"\n",
    "  episode_rewards = []\n",
    "  for episode in tqdm(range(n_eval_episodes)):\n",
    "    if seed:\n",
    "      state = env.reset(seed=seed[episode])\n",
    "    else:\n",
    "      state = env.reset()[0]\n",
    "    step = 0\n",
    "    done = False\n",
    "    total_rewards_ep = 0\n",
    "    \n",
    "    for step in range(max_steps):\n",
    "      # Take the action (index) that have the maximum expected future reward given that state\n",
    "      action = greedy_policy(Q, state)\n",
    "      new_state, reward, done,_, info = env.step(action)\n",
    "      total_rewards_ep += reward\n",
    "        \n",
    "      if done:\n",
    "        break\n",
    "      state = new_state\n",
    "    episode_rewards.append(total_rewards_ep)\n",
    "  mean_reward = np.mean(episode_rewards)\n",
    "  std_reward = np.std(episode_rewards)\n",
    "\n",
    "  return mean_reward, std_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "fAgB7s0HEFMm"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15c632f801724a2694a480042a536f34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_reward=1.00 +/- 0.00\n"
     ]
    }
   ],
   "source": [
    "# Evaluate our Agent\n",
    "mean_reward, std_reward = evaluate_agent(env, max_steps, n_eval_episodes, Qtable_frozenlake, eval_seed)\n",
    "print(f\"Mean_reward={mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Jex3i9lZ8ksX"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi, snapshot_download\n",
    "from huggingface_hub.repocard import metadata_eval_result, metadata_save\n",
    "\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "Qo57HBn3W74O"
   },
   "outputs": [],
   "source": [
    "def record_video(env, Qtable, out_directory, fps=1):\n",
    "  \"\"\"\n",
    "  Generate a replay video of the agent\n",
    "  :param env\n",
    "  :param Qtable: Qtable of our agent\n",
    "  :param out_directory\n",
    "  :param fps: how many frame per seconds (with taxi-v3 and frozenlake-v1 we use 1)\n",
    "  \"\"\"\n",
    "  images = []  \n",
    "  done = False\n",
    "  state = env.reset(seed=random.randint(0,500))[0]\n",
    "  img = env.render()\n",
    "  images.append(img)\n",
    "  while not done:\n",
    "    # Take the action (index) that have the maximum expected future reward given that state\n",
    "    action = np.argmax(Qtable[state][:])\n",
    "    state, reward, done,_, info = env.step(action) # We directly put next_state = state for recording logic\n",
    "    img = env.render()\n",
    "    images.append(img)\n",
    "  imageio.mimsave(out_directory, [np.array(img) for i, img in enumerate(images)], fps=fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "U4mdUTKkGnUd"
   },
   "outputs": [],
   "source": [
    "def push_to_hub(\n",
    "    repo_id, model, env, video_fps=1, local_repo_path=\"hub\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Evaluate, Generate a video and Upload a model to Hugging Face Hub.\n",
    "    This method does the complete pipeline:\n",
    "    - It evaluates the model\n",
    "    - It generates the model card\n",
    "    - It generates a replay video of the agent\n",
    "    - It pushes everything to the Hub\n",
    "\n",
    "    :param repo_id: repo_id: id of the model repository from the Hugging Face Hub\n",
    "    :param env\n",
    "    :param video_fps: how many frame per seconds to record our video replay \n",
    "    (with taxi-v3 and frozenlake-v1 we use 1)\n",
    "    :param local_repo_path: where the local repository is\n",
    "    \"\"\"\n",
    "    _, repo_name = repo_id.split(\"/\")\n",
    "\n",
    "    eval_env = env\n",
    "    api = HfApi()\n",
    "\n",
    "    # Step 1: Create the repo\n",
    "    repo_url = api.create_repo(\n",
    "        repo_id=repo_id,\n",
    "        exist_ok=True,\n",
    "    )\n",
    "\n",
    "    # Step 2: Download files\n",
    "    repo_local_path = Path(snapshot_download(repo_id=repo_id))\n",
    "\n",
    "    # Step 3: Save the model\n",
    "    if env.spec.kwargs.get(\"map_name\"):\n",
    "        model[\"map_name\"] = env.spec.kwargs.get(\"map_name\")\n",
    "        if env.spec.kwargs.get(\"is_slippery\", \"\") == False:\n",
    "            model[\"slippery\"] = False\n",
    "\n",
    "    # Pickle the model\n",
    "    with open((repo_local_path) / \"q-learning.pkl\", \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "    # Step 4: Evaluate the model and build JSON with evaluation metrics\n",
    "    mean_reward, std_reward = evaluate_agent(\n",
    "        eval_env, model[\"max_steps\"], model[\"n_eval_episodes\"], model[\"qtable\"], model[\"eval_seed\"]\n",
    "    )\n",
    "\n",
    "    evaluate_data = {\n",
    "        \"env_id\": model[\"env_id\"],\n",
    "        \"mean_reward\": mean_reward,\n",
    "        \"n_eval_episodes\": model[\"n_eval_episodes\"],\n",
    "        \"eval_datetime\": datetime.datetime.now().isoformat()\n",
    "    }\n",
    "\n",
    "    # Write a JSON file called \"results.json\" that will contain the\n",
    "    # evaluation results\n",
    "    with open(repo_local_path / \"results.json\", \"w\") as outfile:\n",
    "        json.dump(evaluate_data, outfile)\n",
    "\n",
    "    # Step 5: Create the model card\n",
    "    env_name = model[\"env_id\"]\n",
    "    if env.spec.kwargs.get(\"map_name\"):\n",
    "        env_name += \"-\" + env.spec.kwargs.get(\"map_name\")\n",
    "\n",
    "    if env.spec.kwargs.get(\"is_slippery\", \"\") == False:\n",
    "        env_name += \"-\" + \"no_slippery\"\n",
    "\n",
    "    metadata = {}\n",
    "    metadata[\"tags\"] = [env_name, \"q-learning\", \"reinforcement-learning\", \"custom-implementation\"]\n",
    "\n",
    "    # Add metrics\n",
    "    eval = metadata_eval_result(\n",
    "        model_pretty_name=repo_name,\n",
    "        task_pretty_name=\"reinforcement-learning\",\n",
    "        task_id=\"reinforcement-learning\",\n",
    "        metrics_pretty_name=\"mean_reward\",\n",
    "        metrics_id=\"mean_reward\",\n",
    "        metrics_value=f\"{mean_reward:.2f} +/- {std_reward:.2f}\",\n",
    "        dataset_pretty_name=env_name,\n",
    "        dataset_id=env_name,\n",
    "    )\n",
    "\n",
    "    # Merges both dictionaries\n",
    "    metadata = {**metadata, **eval}\n",
    "\n",
    "    model_card = f\"\"\"\n",
    "  # **Q-Learning** Agent playing1 **{env_id}**\n",
    "  This is a trained model of a **Q-Learning** agent playing **{env_id}** .\n",
    "\n",
    "  ## Usage\n",
    "\n",
    "  ```python\n",
    "  \n",
    "  model = load_from_hub(repo_id=\"{repo_id}\", filename=\"q-learning.pkl\")\n",
    "\n",
    "  # Don't forget to check if you need to add additional attributes (is_slippery=False etc)\n",
    "  env = gym.make(model[\"env_id\"])\n",
    "  ```\n",
    "  \"\"\"\n",
    "\n",
    "    evaluate_agent(env, model[\"max_steps\"], model[\"n_eval_episodes\"], model[\"qtable\"], model[\"eval_seed\"])\n",
    "  \n",
    "    readme_path = repo_local_path / \"README.md\"\n",
    "    readme = \"\"\n",
    "    print(readme_path.exists())\n",
    "    if readme_path.exists():\n",
    "        with readme_path.open(\"r\", encoding=\"utf8\") as f:\n",
    "            readme = f.read()\n",
    "    else:\n",
    "        readme = model_card\n",
    "\n",
    "    with readme_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(readme)\n",
    "\n",
    "    # Save our metrics to Readme metadata\n",
    "    metadata_save(readme_path, metadata)\n",
    "\n",
    "    # Step 6: Record a video\n",
    "    video_path = repo_local_path / \"replay.mp4\"\n",
    "    record_video(env, model[\"qtable\"], video_path, video_fps)\n",
    "\n",
    "    # Step 7. Push everything to the Hub\n",
    "    api.upload_folder(\n",
    "        repo_id=repo_id,\n",
    "        folder_path=repo_local_path,\n",
    "        path_in_repo=\".\",\n",
    "    )\n",
    "\n",
    "    print(\"Your model is pushed to the Hub. You can view your model here: \", repo_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "QB5nIcxR8paT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid.\n",
      "Your token has been saved in your configured git credential helpers (manager,store).\n",
      "Your token has been saved to C:\\Users\\Daniy\\.huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "FiMqxqVHg0I4"
   },
   "outputs": [],
   "source": [
    "model = {\n",
    "    \"env_id\": env_id,\n",
    "    \"max_steps\": max_steps,\n",
    "    \"n_training_episodes\": n_training_episodes,\n",
    "    \"n_eval_episodes\": n_eval_episodes,\n",
    "    \"eval_seed\": eval_seed,\n",
    "\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"gamma\": gamma,\n",
    "\n",
    "    \"max_epsilon\": max_epsilon,\n",
    "    \"min_epsilon\": min_epsilon,\n",
    "    \"decay_rate\": decay_rate,\n",
    "\n",
    "    \"qtable\": Qtable_frozenlake\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "5sBo2umnXpPd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'env_id': 'FrozenLake-v1',\n",
       " 'max_steps': 99,\n",
       " 'n_training_episodes': 10000,\n",
       " 'n_eval_episodes': 100,\n",
       " 'eval_seed': [],\n",
       " 'learning_rate': 0.7,\n",
       " 'gamma': 0.95,\n",
       " 'max_epsilon': 1.0,\n",
       " 'min_epsilon': 0.05,\n",
       " 'decay_rate': 0.0005,\n",
       " 'qtable': array([[0.73509189, 0.77378094, 0.77378094, 0.73509189],\n",
       "        [0.73509189, 0.        , 0.81450625, 0.77378094],\n",
       "        [0.77378094, 0.857375  , 0.77378094, 0.81450625],\n",
       "        [0.81450625, 0.        , 0.77378094, 0.77378094],\n",
       "        [0.77378094, 0.81450625, 0.        , 0.73509189],\n",
       "        [0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.9025    , 0.        , 0.81450625],\n",
       "        [0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.81450625, 0.        , 0.857375  , 0.77378094],\n",
       "        [0.81450625, 0.9025    , 0.9025    , 0.        ],\n",
       "        [0.857375  , 0.95      , 0.        , 0.857375  ],\n",
       "        [0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.9025    , 0.95      , 0.857375  ],\n",
       "        [0.9025    , 0.95      , 1.        , 0.9025    ],\n",
       "        [0.        , 0.        , 0.        , 0.        ]])}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "RpOTtSt83kPZ"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ec8bc6759e04e0480c72462e658f114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1d3b033a64b436d8e5c41ffdee21938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d77ec343eed47edae1ded15c5e9961c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Your model is pushed to the Hub. You can view your model here:  https://huggingface.co/AxlDM124/q-FrozenLake-v1-4x4-noSlippery\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "username = \"AxlDM124\"\n",
    "repo_name = \"q-FrozenLake-v1-4x4-noSlippery\"\n",
    "push_to_hub(\n",
    "    repo_id=f\"{username}/{repo_name}\",\n",
    "    model=model,\n",
    "    env=env)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Ji_UrI5l2zzn",
    "67OdoKL63eDD",
    "B2_-8b8z5k54"
   ],
   "private_outputs": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
